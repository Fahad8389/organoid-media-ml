#!/usr/bin/env python3
"""
Generate DATA_DICTIONARY.md from database schema.

Usage:
    python scripts/docs/generate_data_dict.py
"""

import sys
sys.path.insert(0, '.')

import sqlite3
import pandas as pd
from datetime import datetime
from pathlib import Path
from config.paths import DB_PATH, PROJECT_ROOT, PROCESSED_DATA_DIR


def get_table_schema(cursor, table_name):
    """Get column info for a table."""
    cursor.execute(f"PRAGMA table_info({table_name})")
    return cursor.fetchall()


def get_sample_values(cursor, table_name, column_name, limit=3):
    """Get sample values for a column."""
    try:
        cursor.execute(
            f"SELECT DISTINCT {column_name} FROM {table_name} "
            f"WHERE {column_name} IS NOT NULL LIMIT {limit}"
        )
        values = [str(row[0])[:30] for row in cursor.fetchall()]
        return ", ".join(values) if values else "NULL"
    except Exception:
        return "N/A"


def generate_data_dict():
    """Generate the data dictionary markdown file."""

    # Check if database exists
    if not DB_PATH.exists():
        print(f"Error: Database not found at {DB_PATH}")
        print("Please ensure the database exists before running this script.")
        sys.exit(1)

    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # Get all tables
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
    tables = [row[0] for row in cursor.fetchall()]

    # Build markdown content
    lines = [
        "# Data Dictionary",
        "",
        f"> Auto-generated by `scripts/docs/generate_data_dict.py`",
        f"> Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        "",
        "## Database Overview",
        "",
        f"- **Database Path:** `{DB_PATH}`",
        f"- **Total Tables:** {len(tables)}",
        "",
        "## Database Tables",
        "",
    ]

    for table in sorted(tables):
        schema = get_table_schema(cursor, table)
        cursor.execute(f"SELECT COUNT(*) FROM {table}")
        row_count = cursor.fetchone()[0]

        lines.append(f"### {table}")
        lines.append(f"**Rows:** {row_count:,}")
        lines.append("")
        lines.append("| Column | Type | Nullable | Sample Values |")
        lines.append("|--------|------|----------|---------------|")

        for col in schema:
            cid, name, dtype, notnull, default, pk = col
            nullable = "No" if notnull else "Yes"
            pk_marker = " (PK)" if pk else ""
            sample = get_sample_values(cursor, table, name)
            lines.append(f"| {name}{pk_marker} | {dtype or 'TEXT'} | {nullable} | {sample} |")

        lines.append("")

    # Add CSV file documentation if it exists
    csv_path = PROCESSED_DATA_DIR / "master_dataset_v2.csv"
    if csv_path.exists():
        lines.append("---")
        lines.append("")
        lines.append("## CSV Files")
        lines.append("")
        lines.append("### master_dataset_v2.csv")
        lines.append(f"**Location:** `{csv_path}`")
        lines.append("")

        try:
            df = pd.read_csv(csv_path, nrows=5)
            lines.append(f"**Rows:** {len(pd.read_csv(csv_path)):,}")
            lines.append(f"**Columns:** {len(df.columns)}")
            lines.append("")
            lines.append("| Column | Type | Sample |")
            lines.append("|--------|------|--------|")

            for col in df.columns:
                dtype = str(df[col].dtype)
                sample = str(df[col].dropna().iloc[0])[:30] if not df[col].dropna().empty else "NULL"
                lines.append(f"| {col} | {dtype} | {sample} |")

            lines.append("")
        except Exception as e:
            lines.append(f"*Error reading CSV: {e}*")
            lines.append("")

    # Add media factors documentation
    lines.extend([
        "---",
        "",
        "## Media Factor Reference",
        "",
        "| Factor | Type | Unit | Description |",
        "|--------|------|------|-------------|",
        "| egf | Regression | ng/mL | Epidermal Growth Factor concentration |",
        "| y27632 | Binary | 0/1 | ROCK inhibitor presence |",
        "| n_acetyl_cysteine | Binary | 0/1 | Antioxidant presence |",
        "| a83_01 | Binary | 0/1 | TGF-beta inhibitor presence |",
        "| sb202190 | Binary | 0/1 | p38 MAPK inhibitor presence |",
        "| fgf2 | Binary | 0/1 | Fibroblast Growth Factor 2 presence |",
        "| cholera_toxin | Regression | ng/mL | cAMP activator concentration |",
        "| insulin | Binary | 0/1 | Insulin presence |",
        "",
    ])

    conn.close()

    # Write to file
    output_path = PROJECT_ROOT / "docs" / "DATA_DICTIONARY.md"
    output_path.parent.mkdir(exist_ok=True)
    output_path.write_text("\n".join(lines))

    print(f"Generated: {output_path}")
    print(f"  - {len(tables)} tables documented")


if __name__ == "__main__":
    generate_data_dict()
